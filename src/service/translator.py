from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from deep_translator import GoogleTranslator

from src.dependencies.settings import get_settings

class Translator:
    def __init__(self, model="gpt-4o", temperature=0, lang = 'zh-TW') -> None:
        self.llm_init(model, temperature)
        
        self.lang_init(lang)


    def llm_init(self, model, temperature):
        self.llm = ChatOpenAI(
            model=model,
            temperature=temperature,
            api_key=get_settings().gpt_secret_key,
        )
    
    def lang_init(self, lang):
        self.lang = lang
        self.translator = GoogleTranslator(source='auto', target=lang)
    
    def question_solution_prompt(self, question, solution):
        prompt_template = PromptTemplate.from_template("""
The following is the question from user's context and the solution generated by llm.
Question: {question}
Answer and Solution: {solution}
Tranlate the solution into language {language}.
Return the translated answer and solution.

Format Example:
ANSWER: the brief answer of the question
SOLUTION: the solution in bullet point

Make sure the subjects in the question and solution are the same. 
If there are equations in the answer or solution, write the equations in latex format and enclosing with dollar signs ($).
If the language translate to is zh-TW, replace ANSWER and SOLUTION with 答案 and 解析. Begin! 
"""
        )
        return prompt_template.format(question = question, solution=solution, language=self.lang)
    
    def question_prompt(self, question):
        prompt_template = PromptTemplate.from_template("""
Tranlate the following question into language {language}.
Question: {question}
Return the translated Question. Write the equations in latex format and enclosing with dollar signs ($).

Format Example:
QUESTION: the translated question here

If the language translate to is zh-TW, replace QUESTION with 問題. Begin! 
"""
        )
        return prompt_template.format(question = question, language=self.lang)
    
    def llm_translate(self, msg):
        return self.llm.invoke(msg).content
    
    async def allm_translate(self, msg):
        res = await self.llm.ainvoke(msg)
        return res.content

    def translate(self, msg):
        self.llm.invoke(msg).content
        return self.translator.translate(text=msg)