from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from deep_translator import GoogleTranslator

from src.dependencies.settings import get_settings

class Translator:
    def __init__(self, model="gpt-4-1106-preview", temperature=0, lang = 'zh-TW') -> None:
        self.llm_init(model, temperature)
        
        self.lang_init(lang)


    def llm_init(self, model, temperature):
        self.llm = ChatOpenAI(
            model=model,
            temperature=temperature,
            api_key=get_settings().gpt_secret_key,
        )
    
    def lang_init(self, lang):
        self.lang = lang
        self.translator = GoogleTranslator(source='auto', target=lang)
    
    def question_solution_prompt(self, question, solution):
        prompt_template = PromptTemplate.from_template(
            """
            The following is the question from user's context and the solution generated by llm.
            Quesrion: {question}
            Solution: {solution}
            Tranlate the solution into language {language}.
            Return the translated solution only.
            """
        )
        return prompt_template.format(question = question, solution=solution, language=self.lang)
    
    def llm_translate(self, msg):
        return self.llm.invoke(msg).content

    def translate(self, msg):
        self.llm.invoke(msg).content
        return self.translator.translate(text=msg)