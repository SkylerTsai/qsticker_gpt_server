from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from deep_translator import GoogleTranslator

from src.dependencies.settings import get_settings

class Translator:
    def __init__(self, model="gpt-4-1106-preview", temperature=0, lang = 'zh-TW') -> None:
        self.llm_init(model, temperature)
        
        self.lang_init(lang)


    def llm_init(self, model, temperature):
        self.llm = ChatOpenAI(
            model=model,
            temperature=temperature,
            api_key=get_settings().gpt_secret_key,
        )
    
    def lang_init(self, lang):
        self.lang = lang
        self.translator = GoogleTranslator(source='auto', target=lang)
    
    def question_solution_prompt(self, question, solution):
        prompt_template = PromptTemplate.from_template("""
The following is the question from user's context and the solution generated by llm.
Quesrion: {question}
Answer and Solution: {solution}
Tranlate the solution into language {language}.
Return the translated answer and solution.

Format Example:
ANSWER (or 答案): the brief answer of the question
SOLUTION (or 解析)): the solution in bullet point

Make sure the subjects in the question and solution are the same. Begin! 
"""
        )
        return prompt_template.format(question = question, solution=solution, language=self.lang)
    
    def llm_translate(self, msg):
        return self.llm.invoke(msg).content
    
    async def allm_translate(self, msg):
        res = await self.llm.ainvoke(msg)
        return res.content

    def translate(self, msg):
        self.llm.invoke(msg).content
        return self.translator.translate(text=msg)